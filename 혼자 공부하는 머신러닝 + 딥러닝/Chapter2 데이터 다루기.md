# Chapter 2. 데이터 다루기

## 2-1. 훈련 세트와 테스트 세트

### 1) 지도 학습과 비지도 학습
- **지도 학습**: 입력 데이터와 정답(타깃)을 기반으로 모델을 훈련  
  - 입력(input), 타깃(target), 훈련 데이터(training data), 특성(feature)
- **비지도 학습**: 입력 데이터만 사용
- **강화 학습**: 정답 대신 행동의 결과로 얻은 **보상**을 사용해 학습
- 머신러닝 모델의 정확한 평가는 **훈련 세트**와 **테스트 세트**를 분리해야 함
- 데이터셋 링크: [bream_smelt 생선 리스트](http://bit.ly/bream_smelt)
- **샘플링 편향(Sampling Bias)**: 데이터가 공정하지 않게 수집된 경우 발생

### 2) 넘파이
- 파이썬 대표 배열 라이브러리  
- 고차원 배열 조작과 생성에 유용한 함수 제공

#### 주요 기능 및 메서드
- **배열 인덱싱**  
  예: `print(input_arr[[1, 3]])` → 2번째와 4번째 샘플 선택  
- `predict()` 메서드의 반환값은 **넘파이 배열**
- 사이킷런 모델 입출력은 **모두 넘파이 배열**
- `np.seed(n)`: 랜덤 결과 재현을 위한 초기값 설정
- `np.arange(n)`: 0부터 n-1까지 일정 간격 배열 생성
- `np.shuffle()`: 배열의 순서를 무작위로 섞음

### 3) 훈련 모델 평가
- 훈련 데이터로 평가 → 정답을 미리 본 것과 같음 → 신뢰할 수 없음  
  → **테스트 세트는 훈련에 사용하지 않은 데이터여야 함**
- 전체 소스 코드 링크: [hg-02-1 코드](https://bit.ly/hg-02-1)
- 훈련 세트는 **최대한 크게**, 테스트 세트는 보통 **20~30%**

---

## 2-2. 데이터 전처리

### 1) 넘파이로 데이터 준비하기
- 생선 데이터 링크: [bream_smelt](http://bit.ly/bream_smelt)
- `np.column_stack()`: 여러 리스트를 열 방향으로 결합하여 2차원 배열 생성
- **튜플**: 수정 불가. 함수 매개변수로 자주 사용됨
- 넘파이 배열은 행과 열 형태로 자동 정렬되어 출력됨
- `np.concatenate()`: 1차원적으로 배열 연결 (stack과 구분)
- **속도 면에서 넘파이 배열이 파이썬 리스트보다 우수**  
  (핵심 구현이 C/C++로 되어 있음)

### 2) 사이킷런으로 훈련 세트와 테스트 세트 나누기
- 직접 나누는 방식보다 `train_test_split()` 함수 사용
- `random_state`: 동일한 랜덤 분할 재현 가능
- 넘파이 배열의 shape은 **튜플**로 표현됨 (예: `(n, 1)`처럼 콤마로 표시)
- `stratify`: 타깃 값을 기준으로 클래스 비율에 맞춰 분할

### 3) 수상한 도미 한 마리
- K-최근접 이웃은 **거리 계산**을 기반으로 함
- 길이와 무게처럼 **단위가 다른 특성**을 비교하면 거리 계산이 왜곡됨
- → **특성 스케일 맞추기(정규화/표준화)** 필요

#### 표준점수 (Z-score)
- 특정 값이 평균에서 얼마나 떨어져 있는지를 나타냄
- `np.mean()`: 평균, `np.std()`: 표준편차
- `axis=0`: 열 단위 계산, `axis=1`: 행 단위 계산
- **브로드캐스팅**: 연산을 자동으로 모든 행에 적용

### 4) 전처리 데이터로 모델 훈련하기
- 샘플 `[25, 150]` 또한 같은 방식으로 전처리해야 정확한 비교 가능
- 전처리 후에는 산점도의 범위가 -1.5 ~ 1.5로 변화
- 테스트 세트 역시 **훈련 세트의 기준으로 변환**되어야 함
- 결과적으로 스케일에 민감하지 않은 안정적인 예측 가능
- 일반적으로 **표준점수 방식**만으로도 충분한 전처리 효과

---
