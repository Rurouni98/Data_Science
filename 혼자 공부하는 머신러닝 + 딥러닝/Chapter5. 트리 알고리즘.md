# Chapter 5. 트리 알고리즘

## 5-1. 결정 트리 (Decision Tree)

### 1) 로지스틱 회귀로 와인 분류

- `DataFrame.info()`: 데이터프레임의 행, 열, 결측치 여부 등 메타 정보 확인
- `DataFrame.describe()`: 기초 통계 요약 정보 제공
- 주요 통계 지표:
  - **mean**: 평균
  - **std**: 표준편차
  - **min / max**: 최소 / 최대값
  - **25% / 50% / 75%**: 1사분위수, 중간값(2사분위수), 3사분위수

### 2) 결정 트리란?

- **스무고개 게임**처럼 질문을 던져가며 정답을 좁혀가는 방식
- 데이터를 잘 나눌 수 있는 질문을 찾아 **분류 정확도**를 높이는 것이 목표
- 사이킷런 클래스: `DecisionTreeClassifier`

#### 📌 결정 트리 구조 용어

| 용어         | 설명 |
|------------|------|
| 루트 노드    | 트리의 맨 위 노드, 처음 분할되는 기준이 되는 노드 |
| 내부 노드    | 중간에 위치하여 분기를 만드는 노드 |
| 리프 노드    | 더 이상 분할되지 않는 최종 노드, 예측 결과를 나타냄 |

- 시각화 시 `figsize()`를 통해 그림 크기(단위: 인치)를 조정
- 리프 노드를 제한 없이 늘리면 **과대적합(Overfitting)** 발생
- 따라서 **언제까지 이분화를 할지**에 대한 조건 필요 → **가지치기(pruning)**로 제어

#### ✅ 노드 설명 요소

- **test condition**: 노드가 샘플을 분리하는 기준
- **samples**: 현재 노드에 속한 샘플 수
- **value**: 각 클래스별 샘플 수 (예: [양성, 음성])
- 조건 만족 시 왼쪽 자식 노드, 그렇지 않으면 오른쪽 자식 노드로 이동

#### 🌈 시각적 특징

- 클래스 비율이 뚜렷할수록 색이 진하게 표시됨
- 리프 노드에서는 **가장 많은 클래스**가 예측 클래스가 됨

#### 🔎 불순도 개념

- **지니 불순도(Gini Impurity)**:
  
  $$
  \text{Gini} = 1 - \sum_{k=1}^{K} (p_k)^2
  $$

  예: 이진 분류일 경우,  
  $$
  \text{Gini} = 1 - (\text{양성 비율}^2 + \text{음성 비율}^2)
  $$

- **정보 이득(Information Gain)**:  
  부모 노드와 자식 노드 간의 불순도 차이.  
  결정 트리는 **정보 이득이 최대화**되도록 분할

- 사이킷런에서 `criterion='gini'` (기본) 또는 `'entropy'`로 변경 가능

#### ✂️ 가지치기 방법

- `max_depth`, `min_samples_split`, `min_impurity_decrease` 등의 매개변수로 트리 성장 제한 가능
- **결정 트리는 특성 간의 스케일 차이를 신경 쓰지 않음**  
  → **표준화 전처리 불필요**, 오히려 방해될 수 있음

### 3) 핵심 키워드 요약

- **결정 트리**: 예/아니오 기반 질문으로 분류, 설명력이 뛰어난 모델
- **불순도**: 노드 내 데이터의 혼합 정도를 수치화한 기준 (지니, 엔트로피)
- **정보 이득**: 분할로 인해 감소한 불순도의 크기
- **가지치기**: 과대적합 방지를 위한 트리 성장 제한
- **특성 중요도**: 각 특성이 전체 분류 정확도 향상에 기여한 정도

---

## 5-2. 교차 검증과 그리드 서치

### 1) 검증 세트(Validation Set)

- 테스트 세트는 오직 **최종 성능 평가용**으로 사용
- 훈련 중간에 테스트 세트를 자주 확인하면 **테스트 세트에 과적합될 위험**
- 해결책: 훈련 세트에서 일부를 **검증 세트**로 분리하여 하이퍼파라미터 튜닝 및 성능 평가

### 2) 교차 검증 (Cross Validation)

- 훈련 데이터 일부를 검증용으로 사용하면 훈련 데이터 양이 줄어드는 단점
- **교차 검증**은 훈련 세트를 여러 조각으로 나누고, 매번 다른 조각을 검증 세트로 사용하여 반복 평가
- **k-폴드 교차 검증**:
  - 데이터를 k등분하여 k번 반복
  - 각 반복마다 다른 폴드가 검증 세트 역할
  - 결과 평균을 사용하여 안정된 평가 수행

| 폴드 수 | 사용 예시 |
|--------|---------|
| 5      | 일반적인 기본 설정 |
| 10     | 더 안정적인 성능 평가 가능 |

- 사이킷런 함수: `cross_validate()`

#### 🔧 주의사항

- `cross_validate()`는 데이터를 **자동으로 섞지 않음**
- 분할기(splitter) 명시 필요:
  - **회귀**: `KFold`
  - **분류**: `StratifiedKFold` (클래스 비율 유지)

---

### 3) 하이퍼 파라미터 튜닝

#### 📌 용어 정리

| 구분             | 설명 |
|----------------|------|
| 모델 파라미터      | 학습 과정에서 자동으로 조정됨 (ex. 트리의 가중치) |
| 하이퍼 파라미터    | 사용자가 직접 지정해야 함 (ex. max_depth) |

- 다양한 하이퍼파라미터 조합을 실험하고 평가 → 성능 향상 도모

#### 🔍 그리드 서치 (Grid Search)

- 사이킷런 클래스: `GridSearchCV`
- **교차 검증 + 파라미터 조합 탐색**을 한 번에 수행
- `cv=5`가 기본 → 각 조합마다 5번 평가

예: `min_impurity_decrease` 값 5개 × 5-폴드 = **25개 모델 훈련**

- 병렬 처리: `n_jobs=-1` → 모든 CPU 코어 사용
- 결과 활용:
  - `best_estimator_`: 최고 성능 모델
  - `best_params_`: 최적 하이퍼파라미터 조합
  - `best_score_`: 최고 검증 점수

- `argmax()` 등으로 가장 높은 성능의 인덱스 찾기 가능

---

### 3-2) 랜덤 서치 (Random Search)

- 하이퍼파라미터의 범위가 넓거나 세밀한 조정이 어려울 경우 사용
- 지정한 **확률 분포에서 무작위 샘플링**하여 파라미터 설정

#### 📌 분포 함수 예시

- `randint(a, b)`:  
  → `[a, b)` 범위의 **정수**에서 무작위 추출 (이산형 분포)

- `uniform(a, b)`:
  → `[a, a + b]` 범위의 **실수(float)**에서 무작위 추출 (연속형 분포)

- 장점:  
  → 많은 조합을 시도하지 않고도 성능이 좋은 하이퍼파라미터 조합을 빠르게 찾을 수 있음

---

## ✅ 요약

- **결정 트리**는 직관적이고 해석 가능하지만 가지치기를 하지 않으면 과대적합되기 쉬움
- **불순도(지니, 엔트로피)**는 노드 분할 기준이며, 정보 이득은 성능 향상 측정 도구
- **교차 검증**은 모델의 일반화 성능을 안정적으로 평가
- **그리드 서치**는 가능한 모든 하이퍼파라미터 조합을 평가하여 최적 조합을 탐색
- **랜덤 서치**는 조합 수가 많을 때 효율적인 탐색 방법

