# Chapter 3. 회귀 알고리즘과 모델 규제

## 3-1. k-최근접 이웃 회귀

### 1) 데이터 준비
- 회귀: 숫자 예측 문제
- 훈련 세트는 2차원 배열 필수 → reshape(-1, 1)로 처리
- [농어 데이터](http://bit.ly/perch_data) 사용

### 2) 결정계수 R²
- 사이킷런: `KNeighborsRegressor` 사용
- R² (결정계수) = 1에 가까울수록 성능 우수
- `mean_absolute_error`: 예측 오차의 평균 절댓값

### 3) 과대적합 vs 과소적합
- **과대적합**: 훈련 세트에만 잘 맞음
- **과소적합**: 훈련/테스트 모두 낮거나 테스트 점수가 더 높음
- 예시: k=5는 과소적합 → k=3으로 개선

---

## 3-2. 선형 회귀

### 1) KNN의 한계
- 범위를 벗어난 입력에 대해 예측 불가
- 예: 100cm 농어도 1033g으로 예측됨

### 2) 선형 회귀
- 직선 형태의 모델 학습 (`y = ax + b`)
- `LinearRegression` 사용
- `coef_`: 기울기, `intercept_`: 절편
- **모델 기반 학습** vs **사례 기반 학습** (ex: KNN)

### 3) 다항 회귀
- 다항식을 이용한 선형 회귀
- 비선형처럼 보여도 선형 회귀로 처리 가능
- 성능 향상되나 여전히 과소적합

---

## 3-3. 특성 공학과 규제

### 1) 다중 회귀
- 여러 특성을 사용하는 선형 회귀
- **특성 공학**: 기존 특성으로 새로운 특성 생성

### 2) 데이터 준비
- 판다스: 데이터프레임 지원
- `PolynomialFeatures`: 다항 특성 생성기
- `fit()`, `transform()` 메서드 사용
- 테스트 세트도 훈련 세트 기준으로 변환 권장

### 3) 다중 회귀 모델 훈련
- 특성 개수가 많아질수록 성능 변화 큼
- 너무 많으면 **과대적합**, 적으면 **과소적합**
- → **규제** 필요

### 4) 릿지 회귀 (Ridge)
- 계수를 **제곱**하여 규제
- `alpha`: 규제 강도 조절
- 적절한 `alpha`: 훈련/테스트 점수 차이 작고 테스트 점수 높음

### 5) 라쏘 회귀 (Lasso)
- 계수를 0으로 만들 수 있음 → **불필요한 특성 제거 가능**
- `alpha`, `max_iter` 설정
- `coef_` 로 계수 확인